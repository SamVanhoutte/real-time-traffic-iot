{"cells":[{"cell_type":"code","source":["from azure.eventhub import EventData\nfrom azure.eventhub import EventHubClient\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport json\nfrom datetime import datetime"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["## Connection details"],"metadata":{}},{"cell_type":"code","source":["kv_scope = 'key-vault-secret'\n\n# Variables\neventhubs_namespace = dbutils.secrets.get(scope =kv_scope, key = 'traffic-eventhubs-namespace') \neventhubs_accesskey = dbutils.secrets.get(scope =kv_scope, key = 'traffic-eventhubs-accesskey') \neventhubs_accessid = dbutils.secrets.get(scope =kv_scope, key = 'traffic-eventhubs-accessid') \neventhubs_name = dbutils.secrets.get(scope =kv_scope, key = 'traffic-eventhubs-name') \n\n# Build connection string with the above information\ncameraHubConnectionString = 'Endpoint=sb://{}.servicebus.windows.net/;SharedAccessKeyName={};SharedAccessKey={};EntityPath={}'.format(\n  eventhubs_namespace,\n  eventhubs_accessid,\n  eventhubs_accesskey,\n  eventhubs_name)\n\nprint(cameraHubConnectionString)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Endpoint=sb://[REDACTED].servicebus.windows.net/;SharedAccessKeyName=[REDACTED];SharedAccessKey=[REDACTED];EntityPath=[REDACTED]\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["## Event schema definition\n1. Everything is defined as a string, otherwise we get null values"],"metadata":{}},{"cell_type":"code","source":["# Define schema and create incoming camera eventstream\ncameraEventSchema = StructType([ StructField('TrajectId', StringType(), True),\n                      StructField('CameraId', StringType(), True),\n                      StructField('EventTime', StringType(), True),\n                      StructField('Lane', StringType(), True),\n                      StructField('Country', StringType(), True),\n                      StructField('LicensePlate', StringType(), True),\n                      StructField('Make', StringType(), True),\n                      StructField('Color', StringType(), True)])\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["## Configure event hub reader"],"metadata":{}},{"cell_type":"code","source":["# Starting position\nstartingEventPosition = {\n  'offset': '@latest',  \n  'seqNo': -1,            #not in use\n  'enqueuedTime': None,   #not in use\n  'isInclusive': True\n}\n\n# Source with default settings\nehConf = {\n  'eventhubs.connectionString' : cameraHubConnectionString,\n  'eventhubs.consumerGroup': 'db-ingestion',\n  'eventhubs.startingPosition': json.dumps(startingEventPosition),\n  'maxEventsPerTrigger': 5\n}\n\nincomingStream = spark \\\n  .readStream \\\n  .format('eventhubs') \\\n  .options(**ehConf) \\\n  .load()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Transform streams to readable dataframes\n1. First we define the 4 event hubs properties (Offset, Time, Timestamp and Body)\n1. Then, by using the from_json method on the Body property, we apply the above defined schema \n1. After this, we select from the deserialized json the 5 properties which we will ingest\n\nThis is the json we'll get\n```json\n{\"TrajectId\":\"01\",\"CameraId\":\"Camera1\",\"EventTime\":\"2019-12-09T09:59:58.2710792+00:00\",\"Lane\":\"2\",\"Country\":\"BE\",\"LicensePlate\":\"1-KHC-729\",\"Make\":\"Renault\",\"Color\":\"Gray\"}\n```"],"metadata":{}},{"cell_type":"code","source":["# Define parsing query selecting the required properties from the incoming telemetry data\ncameraData = \\\n  incomingStream \\\n  .withColumn('Offset', col('offset')) \\\n  .withColumn('Body', col('body')) \\\n  .withColumn('CameraEvents', from_json(col('Body').cast(StringType()), cameraEventSchema)) \\\n  .withColumn('Time (readable)', col('CameraEvents.EventTime').cast(TimestampType())) \\\n  .withColumn('Timestamp', col('enqueuedTime')) \\\n  .withColumn('TrajectId', col('CameraEvents.TrajectId').cast(StringType())) \\\n  .withColumn('CameraId', col('CameraEvents.CameraId').cast(StringType())) \\\n  .withColumn('EventTime', col('CameraEvents.EventTime').cast(TimestampType())) \\\n  .withColumn('Lane', col('CameraEvents.Lane').cast(IntegerType())) \\\n  .withColumn('Country', col('CameraEvents.Country').cast(StringType())) \\\n  .withColumn('LicensePlate', col('CameraEvents.LicensePlate').cast(StringType())) \\\n  .withColumn('Make', col('CameraEvents.Make').cast(StringType())) \\\n  .withColumn('Color', col('CameraEvents.Color').cast(StringType())) \\\n  .select('TrajectId', 'CameraId', 'EventTime', 'Lane', 'Country', 'LicensePlate', 'Make', 'Color') \\"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["## Stream all iot telemetry to Spark table\n\nThis is needed as having multiple queries on the same EventHub stream would result in epoch issues. \n\nFor this, the [following stackoverflow post](https://stackoverflow.com/questions/54750779/reusing-an-event-hub-stream-for-multiple-queries-in-azure-data-bricks/54761116#54761116) gives more details."],"metadata":{}},{"cell_type":"code","source":["delta_table_name = 'CameraTelemetry' + datetime.today().strftime('%Y%m%d')\nprint('Saving all data in table', delta_table_name)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Saving all data in table CameraTelemetry20200527\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["cameraData.writeStream \\\n  .format('delta') \\\n  .outputMode('append') \\\n  .option('checkpointLocation', '/data/' + delta_table_name + '/_checkpoints/data_file') \\\n  .table(delta_table_name)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7fcd3444fb00&gt;</div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"traffic-camera-ingestion.py","notebookId":2977389562845608},"nbformat":4,"nbformat_minor":0}
